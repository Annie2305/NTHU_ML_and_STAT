{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annie2305/NTHU_ML_and_STAT/blob/main/HW_Prescription_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U9-tSB08WJ2a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqwvCkpeXq-S"
      },
      "source": [
        "Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GO3EAT4uW3bW"
      },
      "outputs": [],
      "source": [
        "path = \"/content/data.xlsx\"\n",
        "df = pd.read_excel(path, header=0)\n",
        "df_shuffled = df.sample(frac = 1, random_state = 42).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS9BXmqbXnPq"
      },
      "source": [
        "# Define Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e_erire3Ww1b"
      },
      "outputs": [],
      "source": [
        "class  NaiveBayes:\n",
        "  def __init__(self, features):\n",
        "      self.prior = {}\n",
        "      self.likelihoods = {}\n",
        "      self.features = features\n",
        "\n",
        "\n",
        "  def fit(self, x, y):\n",
        "      self.classes = list(y.unique())\n",
        "\n",
        "      total = len(y)\n",
        "      for i in self.classes:\n",
        "          count = (y == i).sum() # i 在這個資料集代表 'yes' or 'no'\n",
        "          self.prior[i] = count / total\n",
        "\n",
        "      for feature in self.features:\n",
        "          self.likelihoods[feature] = {}\n",
        "\n",
        "          for i in self.classes:\n",
        "              x_i = x[y == i] # 先篩選出ｉ的類別\n",
        "              counts = x_i[feature].value_counts()\n",
        "              total_i = len(x_i)\n",
        "\n",
        "              for value in counts.index: # value 是特徵的值 e.g. 'Obvious', 'Mild'\n",
        "                  if value not in self.likelihoods[feature]:\n",
        "                      self.likelihoods[feature][value] = {}\n",
        "                  self.likelihoods[feature][value][i] = counts[value] / total_i\n",
        "\n",
        "  def predict(self, x):\n",
        "      posteriors = {}\n",
        "      for i in self.classes:\n",
        "          posteriors[i] = self.prior[i] # 初始化 posterior 值\n",
        "          for feature in self.features:\n",
        "              value = x[feature] # value 是特徵的值ㄋ e.g. 'Obvious', 'Mild'\n",
        "              if value in self.likelihoods[feature] and i in self.likelihoods[feature][value]:\n",
        "                  posteriors[i] = posteriors[i] * self.likelihoods[feature][value][i]\n",
        "\n",
        "      return max(posteriors, key=posteriors.get)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmksn0SBXxNH"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pQIpvJNBW42v"
      },
      "outputs": [],
      "source": [
        "split = int(len(df_shuffled) * 0.8)\n",
        "train = df_shuffled[:split]\n",
        "test = df_shuffled[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efQIF2cbW-l5",
        "outputId": "aa298715-5cff-4a76-e64e-1b04f8651d9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.67\n"
          ]
        }
      ],
      "source": [
        "# training datasets for this model\n",
        "x_train = train[['Weight Loss', 'Headache', 'Fever', 'Cough']]\n",
        "y_train = train['Prescription']\n",
        "\n",
        "# testing datasets for this model\n",
        "x_test = test[['Weight Loss', 'Headache', 'Fever', 'Cough']]\n",
        "y_test = test['Prescription']\n",
        "\n",
        "clf = NaiveBayes(features=['Weight Loss', 'Headache', 'Fever', 'Cough'])\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "# calculate the accuracy\n",
        "correct = 0\n",
        "for i in range(len(x_test)):\n",
        "    x = x_test.iloc[i].to_dict()\n",
        "    y_true = y_test.iloc[i]\n",
        "    y_pred = clf.predict(x)\n",
        "    if y_true == y_pred:\n",
        "        correct += 1\n",
        "\n",
        "accuracy = correct / len(x_test)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt6-EX8GXDpK",
        "outputId": "13e57f49-63f9-4e22-b2d4-f7c3c3c53c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for (Obvious, Yes, No, No): Yes\n"
          ]
        }
      ],
      "source": [
        "# Prediction for the test case from the homework\n",
        "test_case = {\n",
        "    'Weight Loss': 'Obvious',\n",
        "    'Headache': 'Yes',\n",
        "    'Fever': 'No',\n",
        "    'Cough': 'No'\n",
        "}\n",
        "result = clf.predict(test_case)\n",
        "print(f\"Prediction for (Obvious, Yes, No, No): {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr2K6hN5YfrS"
      },
      "source": [
        "# Decision Tree model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y62TjKZGZfJ-"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Iny3jGYmYm6W"
      },
      "outputs": [],
      "source": [
        "class DecisionTree:\n",
        "\n",
        "  def __init__(self, max_depth=None):\n",
        "      self.max_depth = max_depth\n",
        "      self.tree = None\n",
        "\n",
        "  def entropy(self, y):\n",
        "      total = len(y)\n",
        "      counter = Counter(y)\n",
        "      entropy = 0.0\n",
        "      for count in counter.values():\n",
        "          p = count / total\n",
        "          entropy -= p * math.log2(p)\n",
        "      return entropy\n",
        "\n",
        "# information gain 算的是用哪個feature去分類的話 entropy下降的最多\n",
        "  def information_gain(self, X, y, feature):\n",
        "      entropy_before = self.entropy(y)\n",
        "      values = X[feature].unique()\n",
        "\n",
        "      weighted_entropy = 0.0\n",
        "      for value in values:\n",
        "          y_sub = y[X[feature] == value]\n",
        "          weight = len(y_sub) / len(y) #加權\n",
        "          entropy_sub = self.entropy(y_sub)\n",
        "          weighted_entropy += weight * entropy_sub\n",
        "\n",
        "      return entropy_before - weighted_entropy\n",
        "\n",
        "  def fit(self, X, y):\n",
        "      self.tree = self._build_tree(X, y, depth=0)\n",
        "\n",
        "  def _build_tree(self, X, y, depth):\n",
        "\n",
        "      if len(set(y)) == 1:\n",
        "        return y.iloc[0]\n",
        "      if X.shape[1] == 0:\n",
        "        return y.value_counts().idxmax\n",
        "\n",
        "\n",
        "      best_feature = None\n",
        "      best_gain = 0\n",
        "\n",
        "      for feature in X.columns:\n",
        "          gain = self.information_gain(X, y, feature)\n",
        "\n",
        "          if gain > best_gain:\n",
        "              best_gain = gain\n",
        "              best_feature = feature\n",
        "\n",
        "      if best_feature is None:\n",
        "        return y.value_counts().idxmax()\n",
        "\n",
        "      if self.max_depth is not None and depth >= self.max_depth:\n",
        "        return y.value_counts().idxmax()\n",
        "\n",
        "      tree = {best_feature: {}}\n",
        "      feature_values = X[best_feature].unique()\n",
        "\n",
        "      for value in feature_values: #跑該feature的每個值\n",
        "          x_sub = X[X[best_feature] == value].drop(columns = [best_feature]) #把重複的feature拿掉 避免重複分類\n",
        "          y_sub = y[X[best_feature] == value]\n",
        "          subtree = self._build_tree(x_sub, y_sub, depth+1) #用剛剛選出的子資料繼續遞迴建樹（建子樹）\n",
        "          tree[best_feature][value] = subtree #把這個 value 對應的子樹加進來\n",
        "\n",
        "      return tree\n",
        "\n",
        "  def predict(self, X):\n",
        "      node = self.tree\n",
        "\n",
        "      while isinstance(node, dict):\n",
        "          feature = next(iter(node))  # 目前節點的 feature 名稱\n",
        "          value = X.get(feature)\n",
        "\n",
        "          # 防錯：如果 value 是 None 或沒在 tree 中，就中止\n",
        "          if value is None or value not in node[feature]:\n",
        "              return max(set(y_train), key=list(y_train).count)\n",
        "\n",
        "          node = node[feature][value]\n",
        "\n",
        "      if callable(node):\n",
        "        return node()\n",
        "\n",
        "      return node\n",
        "\n",
        "  def predict_all(self, X):\n",
        "\n",
        "      predictions = []\n",
        "\n",
        "      for _, row in X.iterrows():\n",
        "          prediction = self.predict(row)\n",
        "          predictions.append(prediction)\n",
        "      return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qt8xPZkv_0aK"
      },
      "outputs": [],
      "source": [
        "split = int(len(df_shuffled) * 0.8)\n",
        "train = df_shuffled[:split]\n",
        "test = df_shuffled[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiN_cfhM_2Ar",
        "outputId": "adb3a0d2-6cb7-44ee-db2c-d6c70afda9a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.33\n"
          ]
        }
      ],
      "source": [
        "x_train = train[['Weight Loss', 'Headache', 'Fever', 'Cough']]\n",
        "y_train = train['Prescription']\n",
        "\n",
        "x_test = test[['Weight Loss', 'Headache', 'Fever', 'Cough']]\n",
        "y_test = test['Prescription']\n",
        "\n",
        "clf = DecisionTree()\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "y_preds = clf.predict_all(x_test)\n",
        "\n",
        "correct = sum(p == t for p, t in zip(y_preds, y_test))\n",
        "accuracy = correct / len(y_test)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXkgeEBTilVn"
      },
      "source": [
        "**Prediction for the test case from the homework**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lukGBCKZCtMr",
        "outputId": "f6b9be08-9a09-4689-8489-9cd2ed9661a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for (Obvious, Yes, No, No): Yes\n"
          ]
        }
      ],
      "source": [
        "test_case = {\n",
        "    'Weight Loss': 'Obvious',\n",
        "    'Headache': 'Yes',\n",
        "    'Fever': 'No',\n",
        "    'Cough': 'No'\n",
        "}\n",
        "result = clf.predict(test_case)\n",
        "print(f\"Prediction for (Obvious, Yes, No, No): {result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63Z49s4QC706",
        "outputId": "e667eec4-19aa-4599-9f24-499023808625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Weight Loss = No]\n",
            "  [Headache = No]\n",
            "    → Yes\n",
            "  [Headache = Yes]\n",
            "    → No\n",
            "[Weight Loss = Obvious]\n",
            "  [Fever = Yes]\n",
            "    → Yes\n",
            "  [Fever = No]\n",
            "    [Headache = Yes]\n",
            "      → Yes\n",
            "    [Headache = No]\n",
            "      → No\n",
            "[Weight Loss = Mild]\n",
            "  [Cough = No]\n",
            "    → <bound method Series.idxmax of Prescription\n",
            "Yes    1\n",
            "No     1\n",
            "Name: count, dtype: int64>\n",
            "  [Cough = Yes]\n",
            "    → No\n"
          ]
        }
      ],
      "source": [
        "def print_tree(tree, indent=''):\n",
        "    if not isinstance(tree, dict):\n",
        "        print(indent + '→', tree)\n",
        "        return\n",
        "    for feature, branches in tree.items():\n",
        "        for value, subtree in branches.items():\n",
        "            print(f\"{indent}[{feature} = {value}]\")\n",
        "            print_tree(subtree, indent + '  ')\n",
        "\n",
        "print_tree(clf.tree)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGJtkaKsE1E3"
      },
      "source": [
        "**The entropy H(Prescription)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL7BNy57E4qB",
        "outputId": "d4aa77fc-635d-4702-9fd1-059f5e98922e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9852281360342515"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def entropy(y):\n",
        "\n",
        "  total = len(y)\n",
        "  counter = Counter(y)\n",
        "  entropy = 0\n",
        "\n",
        "  for count in counter.values():\n",
        "    p = count/total\n",
        "    entropy += -p * math.log2(p)\n",
        "\n",
        "  return entropy\n",
        "\n",
        "entropy(df['Prescription'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwZGyst2FN7m"
      },
      "source": [
        "**The entropy H(Prescription | Weight Loss)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4gZoWMmFQhY",
        "outputId": "7ef5573d-fe9e-4934-bc23-f3b762fe89ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8221267860233525\n"
          ]
        }
      ],
      "source": [
        "weighted_entropy = 0\n",
        "\n",
        "#在每個 weight loss 類別中 prescription有多混亂 然後加權平均\n",
        "for value in df['Weight Loss'].unique():\n",
        "  y_sub = df[df['Weight Loss'] == value]['Prescription']\n",
        "  weight = len(y_sub) / len(df)\n",
        "  entropy_sub = entropy(y_sub)\n",
        "  weighted_entropy += weight * entropy_sub\n",
        "\n",
        "print(weighted_entropy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P_hgEbZFiSZ"
      },
      "source": [
        "**The entropy H(Prescription | Headache)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdKemSiXFycc",
        "outputId": "e616e417-6743-4258-d441-65d8a1ea05cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9460794641311808\n"
          ]
        }
      ],
      "source": [
        "weighted_entropy = 0\n",
        "\n",
        "#在每個 headache 類別中 prescription有多混亂 然後加權平均\n",
        "for value in df['Headache'].unique():\n",
        "  y_sub = df[df['Headache'] == value]['Prescription']\n",
        "  weight = len(y_sub)/len(df)\n",
        "  entropy_sub = entropy(y_sub)\n",
        "  weighted_entropy += weight * entropy_sub\n",
        "\n",
        "print(weighted_entropy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asUGprnFemrw"
      },
      "source": [
        "**Try scikit-learn's implementation as a benchmark**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WduD82WeNdZ",
        "outputId": "95e17aed-a2e0-4fa0-c335-d82aa8c1bc7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Scikit-learn Decision Tree Accuracy: 0.33\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# convert strings to float\n",
        "x_train_encoded = pd.get_dummies(x_train)\n",
        "x_test_encoded = pd.get_dummies(x_test)\n",
        "\n",
        "# make sure test data has all the columns from training data\n",
        "for col in x_train_encoded.columns:\n",
        "    if col not in x_test_encoded.columns:\n",
        "        x_test_encoded[col] = 0\n",
        "x_test_encoded = x_test_encoded[x_train_encoded.columns]\n",
        "\n",
        "sklearn_dt = DecisionTreeClassifier(random_state=42)\n",
        "sklearn_dt.fit(x_train_encoded, y_train)\n",
        "\n",
        "y_pred = sklearn_dt.predict(x_test_encoded)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nScikit-learn Decision Tree Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhxRSgKme-jA"
      },
      "source": [
        "The test accuracy from the Decision tree model only reached 0.33. it may due to the small dataset size. With limited examples, the decision tree doesn't have enough data to learn reliable patterns. Decision trees typically need more data than Naive Bayes to generalize well. Naive Bayes model performs better (0.67 accuracy) because it makes the \"naive\" assumption of feature independence. This assumption might actually work better with limited data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNWQZ5Bkp7oh123/c1XyuXG",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
