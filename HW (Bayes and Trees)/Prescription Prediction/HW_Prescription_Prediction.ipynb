{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP07Wb9GCTSASAhjfLrjQP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annie2305/NTHU_ML_and_STAT/blob/main/HW_Prescription_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9-tSB08WJ2a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read Data"
      ],
      "metadata": {
        "id": "DqwvCkpeXq-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/data.xlsx\"\n",
        "df = pd.read_excel(path, header=0)\n",
        "df_shuffled = df.sample(frac = 1, random_state = 42).reset_index(drop = True)"
      ],
      "metadata": {
        "id": "GO3EAT4uW3bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Naive Bayes"
      ],
      "metadata": {
        "id": "xS9BXmqbXnPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class  NaiveBayes:\n",
        "  def __init__(self, features):\n",
        "      self.prior = {}\n",
        "      self.likelihoods = {}\n",
        "      self.features = features\n",
        "\n",
        "\n",
        "  def fit(self, x, y):\n",
        "      self.classes = list(y.unique())\n",
        "\n",
        "      total = len(y)\n",
        "      for i in self.classes:\n",
        "          count = (y == i).sum() # i 在這個資料集代表 'yes' or 'no'\n",
        "          self.prior[i] = count / total\n",
        "\n",
        "      for feature in self.features:\n",
        "          self.likelihoods[feature] = {}\n",
        "\n",
        "          for i in self.classes:\n",
        "              x_i = x[y == i] # 先篩選出ｉ的類別\n",
        "              counts = x_i[feature].value_counts()\n",
        "              total_i = len(x_i)\n",
        "\n",
        "              for value in counts.index: # value 是特徵的值 e.g. 'Obvious', 'Mild'\n",
        "                  if value not in self.likelihoods[feature]:\n",
        "                      self.likelihoods[feature][value] = {}\n",
        "                  self.likelihoods[feature][value][i] = counts[value] / total_i\n",
        "\n",
        "  def predict(self, x):\n",
        "      posteriors = {}\n",
        "      for i in self.classes:\n",
        "          posteriors[i] = self.prior[i] # 初始化 posterior 值\n",
        "          for feature in self.features:\n",
        "              value = x[feature] # value 是特徵的值ㄋ e.g. 'Obvious', 'Mild'\n",
        "              if value in self.likelihoods[feature] and i in self.likelihoods[feature][value]:\n",
        "                  posteriors[i] = posteriors[i] * self.likelihoods[feature][value][i]\n",
        "\n",
        "      return max(posteriors, key=posteriors.get)"
      ],
      "metadata": {
        "id": "e_erire3Ww1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "Kmksn0SBXxNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(len(df_shuffled) * 0.8)\n",
        "train = df_shuffled[:split]\n",
        "test = df_shuffled[split:]"
      ],
      "metadata": {
        "id": "pQIpvJNBW42v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training datasets for this model\n",
        "x_train = train[['Weight Loss', 'Headache', 'Fever', 'Cough']]\n",
        "y_train = train['Prescription']\n",
        "\n",
        "# testing datasets for this model\n",
        "x_test = test[['Weight Loss', 'Headache', 'Fever', 'Cough']]\n",
        "y_test = test['Prescription']\n",
        "\n",
        "clf = NaiveBayes(features=['Weight Loss', 'Headache', 'Fever', 'Cough'])\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "# calculate the accuracy\n",
        "correct = 0\n",
        "for i in range(len(x_test)):\n",
        "    x = x_test.iloc[i].to_dict()\n",
        "    y_true = y_test.iloc[i]\n",
        "    y_pred = clf.predict(x)\n",
        "    if y_true == y_pred:\n",
        "        correct += 1\n",
        "\n",
        "accuracy = correct / len(x_test)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efQIF2cbW-l5",
        "outputId": "3a67fe69-4463-4a25-af86-a33106d1c134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction for the test case from the homework\n",
        "test_case = {\n",
        "    'Weight Loss': 'Obvious',\n",
        "    'Headache': 'Yes',\n",
        "    'Fever': 'No',\n",
        "    'Cough': 'No'\n",
        "}\n",
        "result = clf.predict(test_case)\n",
        "print(f\"Prediction for (Obvious, Yes, No, No): {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt6-EX8GXDpK",
        "outputId": "0e6fe7f2-c2fd-4860-ac3d-e3fe960294c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for (Obvious, Yes, No, No): Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree model"
      ],
      "metadata": {
        "id": "Hr2K6hN5YfrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "y62TjKZGZfJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "\n",
        "  def __init__(self, max_depth=None):\n",
        "      self.max_depth = max_depth\n",
        "      self.tree = None\n",
        "\n",
        "  def entropy(self, y):\n",
        "      total = len(y)\n",
        "      counter = Counter(y)\n",
        "      entropy = 0.0\n",
        "      for count in counter.values():\n",
        "          p = count / total\n",
        "          entropy -= p * math.log2(p)\n",
        "      return entropy\n",
        "\n",
        "# information gain 算的是用哪個feature去分類的話 entropy下降的最多\n",
        "  def information_gain(self, X, y, feature):\n",
        "      entropy_before = self.entropy(y)\n",
        "      values = X[feature].unique()\n",
        "\n",
        "      weighted_entropy = 0.0\n",
        "      for value in values:\n",
        "          y_sub = y[X[feature] == value]\n",
        "          weight = len(y_sub) / len(y) #加權\n",
        "          entropy_sub = self.entropy(y_sub)\n",
        "          weighted_entropy += weight * entropy_sub\n",
        "\n",
        "      return entropy_before - weighted_entropy\n",
        "\n",
        "  def fit(self, X, y):\n",
        "      self.tree = self._build_tree(X, y, depth=0)\n",
        "\n",
        "  def _build_tree(self, X, y, depth):\n",
        "\n",
        "      if len(set(y)) == 1:\n",
        "        return y.iloc[0]\n",
        "      if X.shape[1] == 0:\n",
        "        return y.value_counts().idxmax\n",
        "\n",
        "\n",
        "      best_feature = None\n",
        "      best_gain = 0\n",
        "\n",
        "      for feature in X.columns:\n",
        "          gain = self.information_gain(X, y, feature)\n",
        "\n",
        "          if gain > best_gain:\n",
        "              best_gain = gain\n",
        "              best_feature = feature\n",
        "\n",
        "      if best_feature is None:\n",
        "        return y.value_counts().idxmax\n",
        "\n",
        "      tree = {best_feature: {}}\n",
        "      feature_values = X[best_feature].unique()\n",
        "\n",
        "      for value in feature_values: #跑該feature的每個值\n",
        "          x_sub = X[X[best_feature] == value].drop(columns = [best_feature]) #把重複的feature拿掉 避免重複分類\n",
        "          y_sub = y[X[best_feature] == value]\n",
        "          subtree = self._build_tree(x_sub, y_sub, depth+1) #用剛剛選出的子資料繼續遞迴建樹（建子樹）\n",
        "          tree[best_feature][value] = subtree #把這個 value 對應的子樹加進來\n",
        "\n",
        "      return tree\n",
        "\n",
        "  def predict(self, X):\n",
        "      node = self.tree\n",
        "\n",
        "      while isinstance(node, dict):\n",
        "          feature = next(iter(node))  # 目前節點的 feature 名稱\n",
        "          value = X.get(feature)\n",
        "\n",
        "          # 防錯：如果 value 是 None 或沒在 tree 中，就中止\n",
        "          if value is None or value not in node[feature]:\n",
        "              return None\n",
        "\n",
        "          node = node[feature][value]\n",
        "\n",
        "      return node\n",
        "\n",
        "  def predict_all(self, X):\n",
        "\n",
        "      predictions = []\n",
        "\n",
        "      for _, row in X.iterrows():\n",
        "          prediction = self.predict(row)\n",
        "          predictions.append(prediction)\n",
        "      return predictions"
      ],
      "metadata": {
        "id": "Iny3jGYmYm6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(len(df_shuffled) * 0.8)\n",
        "train = df_shuffled[:split]\n",
        "test = df_shuffled[split:]"
      ],
      "metadata": {
        "id": "qt8xPZkv_0aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train[['Weight Loss', 'Headache', 'Fever', 'Cough']]\n",
        "y_train = train['Prescription']\n",
        "\n",
        "x_test = test[['Weight Loss', 'Headache', 'Fever', 'Cough']]\n",
        "y_test = test['Prescription']\n",
        "\n",
        "clf = DecisionTree()\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "y_preds = clf.predict_all(x_test)\n",
        "\n",
        "correct = sum(p == t for p, t in zip(y_preds, y_test))\n",
        "accuracy = correct / len(y_test)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiN_cfhM_2Ar",
        "outputId": "0d415db8-4567-44d2-f787-6cdd35f1e1ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction for the test case from the homework"
      ],
      "metadata": {
        "id": "PXkgeEBTilVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_case = {\n",
        "    'Weight Loss': 'Obvious',\n",
        "    'Headache': 'Yes',\n",
        "    'Fever': 'No',\n",
        "    'Cough': 'No'\n",
        "}\n",
        "result = clf.predict(test_case)\n",
        "print(f\"Prediction for (Obvious, Yes, No, No): {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lukGBCKZCtMr",
        "outputId": "eba67cbb-7c27-4f4f-88a3-3d8470709880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for (Obvious, Yes, No, No): Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_tree(tree, indent=''):\n",
        "    if not isinstance(tree, dict):\n",
        "        print(indent + '→', tree)\n",
        "        return\n",
        "    for feature, branches in tree.items():\n",
        "        for value, subtree in branches.items():\n",
        "            print(f\"{indent}[{feature} = {value}]\")\n",
        "            print_tree(subtree, indent + '  ')\n",
        "\n",
        "print_tree(clf.tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63Z49s4QC706",
        "outputId": "4d27e339-b5fb-4800-8563-c19b894229f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Weight Loss = No]\n",
            "  [Headache = No]\n",
            "    → Yes\n",
            "  [Headache = Yes]\n",
            "    → No\n",
            "[Weight Loss = Obvious]\n",
            "  [Fever = Yes]\n",
            "    → Yes\n",
            "  [Fever = No]\n",
            "    [Headache = Yes]\n",
            "      → Yes\n",
            "    [Headache = No]\n",
            "      → No\n",
            "[Weight Loss = Mild]\n",
            "  [Cough = No]\n",
            "    → <bound method Series.idxmax of Prescription\n",
            "Yes    1\n",
            "No     1\n",
            "Name: count, dtype: int64>\n",
            "  [Cough = Yes]\n",
            "    → No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The entropy H(Prescription)**"
      ],
      "metadata": {
        "id": "VGJtkaKsE1E3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(y):\n",
        "\n",
        "  total = len(y)\n",
        "  counter = Counter(y)\n",
        "  entropy = 0\n",
        "\n",
        "  for count in counter.values():\n",
        "    p = count/total\n",
        "    entropy += -p * math.log2(p)\n",
        "\n",
        "  return entropy\n",
        "\n",
        "entropy(df['Prescription'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL7BNy57E4qB",
        "outputId": "d04cf277-8540-4fc9-d2e2-5b979e19668d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9852281360342515"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The entropy H(Prescription | Weight Loss)**"
      ],
      "metadata": {
        "id": "bwZGyst2FN7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_entropy = 0\n",
        "\n",
        "#在每個 weight loss 類別中 prescription有多混亂 然後加權平均\n",
        "for value in df['Weight Loss'].unique():\n",
        "  y_sub = df[df['Weight Loss'] == value]['Prescription']\n",
        "  weight = len(y_sub) / len(df)\n",
        "  entropy_sub = entropy(y_sub)\n",
        "  weighted_entropy += weight * entropy_sub\n",
        "\n",
        "print(weighted_entropy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4gZoWMmFQhY",
        "outputId": "3ecba71c-e3d1-49ad-dfa3-5dede8a9b880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8221267860233525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The entropy H(Prescription | Headache)**"
      ],
      "metadata": {
        "id": "8P_hgEbZFiSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_entropy = 0\n",
        "\n",
        "#在每個 headache 類別中 prescription有多混亂 然後加權平均\n",
        "for value in df['Headache'].unique():\n",
        "  y_sub = df[df['Headache'] == value]['Prescription']\n",
        "  weight = len(y_sub)/len(df)\n",
        "  entropy_sub = entropy(y_sub)\n",
        "  weighted_entropy += weight * entropy_sub\n",
        "\n",
        "print(weighted_entropy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdKemSiXFycc",
        "outputId": "79009ec9-adcf-412d-8da0-9599999178e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9460794641311808\n"
          ]
        }
      ]
    }
  ]
}